{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# # Required Packages for the Project RUN ONLY ONCE\n",
    "# %pip install matplotlib\n",
    "# %pip install nilearn\n",
    "# %pip install openpyxl\n",
    "# %pip install Path\n",
    "# %pip install seaborn\n",
    "# %pip install nltools\n",
    "# %pip install scipy\n",
    "# %pip install scikit-image\n",
    "# %pip install nibabel\n",
    "# %pip install bctpy\n",
    "# %pip install statsmodels\n",
    "# %pip install import-ipynb\n",
    "# %pip install ipynb\n",
    "# %pip install fitz\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.graphMetrics import GraphMetrics\n",
    "from modules.helpers import *\n",
    "from modules.subject import GroupsInfo\n",
    "from modules.voxel import VoxelCounts\n",
    "from modules.crossCorrelation import CorrsCorrelations\n",
    "from modules.createPDF import PDF\n",
    "import traceback\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='app.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s', level=logging.DEBUG)\n",
    "logging.warning('Starting Application....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    subjectsData = GroupsInfo.getInstance()\n",
    "    voxels = VoxelCounts.getInstance()\n",
    "    graphMetrics = GraphMetrics.getInstance()\n",
    "    # crossCorr = CorrsCorrelations(subjectsData, voxels, graphMetrics)\n",
    "except:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedures on voxels data\n",
    "voxels.calculateVoxelCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedures on graphMetrics data\n",
    "# graphMetrics.calculateGraphMetrics()\n",
    "graphMetrics.calAvgAllGroupFNC('values/Weighted-0.15/FNC/groups/')\n",
    "graphMetrics.calDiffAvgGroupFNC('values/Weighted-0.15/FNC/differences/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossCorrelation = CorrsCorrelations(subjectsData, voxels, graphMetrics)\n",
    "crossCorrelation.calculateStatsCrossCorrelation()\n",
    "crossCorrelation.calculateDifferencePvalues()\n",
    "crossCorrelation.saveCrossCorrelation('values/Weighted-0.15/crossCorrelation/groups/')\n",
    "crossCorrelation.saveDifferenceCrossCorrelation('values/Weighted-0.15/crossCorrelation/differences/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "gm = dict()\n",
    "measures = subjectsData.getGlobalGraphMetrics()\n",
    "groups = list(subjectsData.getGroupDictionary().keys())\n",
    "\n",
    "for i in groups:\n",
    "    gm[i] = dict()\n",
    "    gm[i][measures[0]] = round(computeGlobalEfficiency(numpyMatrix(graphMetrics.avgFNCs[i])),3)\n",
    "    gm[i][measures[1]] = round(computeCharacteristicPathLength(numpyMatrix(graphMetrics.avgFNCs[i])),3)\n",
    "    gm[i][measures[2]] = round(computeClusteringCoefficient(numpyMatrix(graphMetrics.avgFNCs[i])),3)\n",
    "\n",
    "ge_values = pd.DataFrame(gm)\n",
    "ge_values.to_csv('values/Weighted-0.15/global_values/globalMetrics.txt', sep=',')\n",
    "\n",
    "groupsMod = list()\n",
    "for i in range(len(groups)):\n",
    "    for j in range(i+1, len(groups)):\n",
    "        groupsMod.append(groups[i]+'/'+groups[j])\n",
    "\n",
    "t_dict = dict()\n",
    "p_dict = dict()\n",
    "\n",
    "for i in measures:\n",
    "    t_dict[i]=dict()\n",
    "    p_dict[i] = dict()\n",
    "    for g1 in range(len(groups)):\n",
    "        v1 = graphMetrics.graphMetricMap[groups[g1]][i]\n",
    "        for g2 in range(g1+1, len(groups)):\n",
    "            v2 = graphMetrics.graphMetricMap[groups[g2]][i]\n",
    "            \n",
    "            key1 = groups[g1]+'/'+groups[g2]\n",
    "            mean_1, mean_2 = gm[groups[g1]][i],gm[groups[g2]][i]\n",
    "            t_test = two_Sample_t_test(v1, v2, mean_1, mean_2)\n",
    "            t_dict[i][key1] = t_test[0]\n",
    "            p_dict[i][key1] = t_test[1]\n",
    "\n",
    "t_values, p_values = pd.DataFrame(t_dict), pd.DataFrame(p_dict)\n",
    "t_values.to_csv('values/Weighted-0.15/global_values/t_values.txt', sep=',')\n",
    "p_values.to_csv('values/Weighted-0.15/global_values/p_values.txt', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "measures = subjectsData.getComponentGraphMetrics()\n",
    "groups = list(subjectsData.getGroupDictionary().keys())\n",
    "indexes = subjectsData.getICNIndexes()\n",
    "domainList = subjectsData.getICNDomainNames()\n",
    "\n",
    "def createList(series):\n",
    "    ans = list()\n",
    "    for i in range(53):\n",
    "        ans.append(round(series[i], 5))\n",
    "    return ans\n",
    "\n",
    "for i in measures:\n",
    "    df = prepareDataFrame(indexes, domainList)\n",
    "    for j in groups:\n",
    "        if i == \"Degree\":\n",
    "            df.loc[len(df.index)] = createList(computeDegree(numpyMatrix(graphMetrics.avgFNCs[j])))\n",
    "\n",
    "        elif i == \"Closeness centrality\":\n",
    "            df.loc[len(df.index)] = createList(computeClosenessCentrality(numpyMatrix(graphMetrics.avgFNCs[j])))\n",
    "\n",
    "        else:\n",
    "            df.loc[len(df.index)] = createList(computeParticipationCoefficient(numpyMatrix(graphMetrics.avgFNCs[j])))\n",
    "\n",
    "    df.index = groups\n",
    "    # logging.info(df)\n",
    "\n",
    "    vmin, vmax = 100, -100\n",
    "    vmin = min( vmin, min(df.min().values))\n",
    "    vmax = max( vmax, max(df.max().values) )\n",
    "    logging.info(\"measure: %s, vmin: %s, vmax: %s\", i, vmin, vmax)\n",
    "    if i == \"Closeness centrality\": \n",
    "        vmin, vmax = 0.55000, 0.66000\n",
    "    elif i == \"Participation coefficient\":\n",
    "        vmin, vmax = 0.89900, 0.95789\n",
    "    else:\n",
    "        vmin = min( vmin, min(df.min().values))\n",
    "        vmax = max( vmax, max(df.max().values) )\n",
    "\n",
    "    print(list(df.columns))\n",
    "    prepareHeatmap(\n",
    "        list(df.columns),\n",
    "        groups,\n",
    "        df,\n",
    "        i,\n",
    "        'values/Weighted-0.15/global_values/',\n",
    "        vmin,\n",
    "        vmax,\n",
    "        figsize=(8,3)\n",
    "    )\n",
    "\n",
    "    diffDt = prepareDataFrame(indexes, domainList)\n",
    "    rows = df.index.values\n",
    "    columns = df.columns.values\n",
    "\n",
    "    newRowList = list()\n",
    "    for r1 in range(len(rows)):\n",
    "        for r2 in range(r1+1, len(rows)):\n",
    "\n",
    "            diffList = list()\n",
    "            newRowList.append(rows[r1]+'-'+rows[r2])\n",
    "            for col in columns:\n",
    "                diffList.append(round(df.at[rows[r1], col] - df.at[rows[r2], col], 3))\n",
    "\n",
    "            diffDt.loc[len(diffDt.index)] = diffList\n",
    "\n",
    "    diffDt.index = newRowList\n",
    "    logging.info(\"Differences: measure: %s\", i)\n",
    "    logging.info(diffDt)\n",
    "\n",
    "    vmin = min( vmin, min(diffDt.min().values))\n",
    "    vmax = max( vmax, max(diffDt.max().values) )\n",
    "    logging.info(\"measure: %s, vmin: %s, vmax: %s\", i, vmin, vmax)\n",
    "\n",
    "    greaterVal = max(abs(vmin), abs(vmax))\n",
    "    vmin, vmax = -1*greaterVal, greaterVal\n",
    "\n",
    "    prepareHeatmap(\n",
    "        list(diffDt.columns),\n",
    "        groups,\n",
    "        diffDt,\n",
    "        i+'-Difference',\n",
    "        'values/Weighted-0.15/global_values/',\n",
    "        vmin,\n",
    "        vmax,\n",
    "        figsize=(8,3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getGlobalGraphMetricsForAvgFNCs(graphMetrics, 'values/Weighted-0.15/global_values/', 'Global Metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "100x100 -> 53x53\n",
    "    69  53  98  99  45 . . . . . . . .\n",
    "69  0   X   X1  x03 x04 ...............\n",
    "53  -   x11 x12 x13 x14 . . . . . \n",
    "98  -   -   x22 x23 x24 . . . . .\n",
    "99\n",
    "45\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "Transpose -> 53x53 FNC-matrix\n",
    "\n",
    "CrossCorrelation:\n",
    "entire 69th & 53th -> PearsonCrossCorrelation -> X\n",
    "> 0.15 or 0 -> Thresholding\n",
    "\n",
    "\n",
    "Global Metrics:\n",
    "Entire 53X53 -> \n",
    "1 FNC = Y value\n",
    "\n",
    "CN: [ s_1_X, s_2_X, s_3_X, ..... 900]\n",
    "AD: [ s_1_X, s_2_X, s_3_X, ..... 200]\n",
    "MCI: [ s_1_X, s_2_X, s_3_X, ..... 300]\n",
    "\n",
    "Component Metrics:\n",
    "Entire 53x53 -> 53 Values \n",
    "1 FNC = [ a1, a2, a3, a4,......]\n",
    "\n",
    "CN:\n",
    "    69: [s_1_0, s_2_0, ....., 900]\n",
    "    53: [s_1_1, s_2_1]\n",
    "    98: [s_1_2, s_2_2]\n",
    "    99: [s_1_3, s_2_3]\n",
    "    45: [s_1_4, s_2_4]\n",
    "AD:\n",
    "    69: [s_1_0, s_2_0, ....., 200]\n",
    "    53: [s_1_1, s_2_1]\n",
    "    98: [s_1_2, s_2_2]\n",
    "    99: [s_1_3, s_2_3]\n",
    "    45: [s_1_4, s_2_4]\n",
    "\n",
    "MCI:\n",
    "    69: [s_1_0, s_2_0, ....., 300]\n",
    "    53: [s_1_1, s_2_1]\n",
    "    98: [s_1_2, s_2_2]\n",
    "    99: [s_1_3, s_2_3]\n",
    "    45: [s_1_4, s_2_4]\n",
    "\n",
    "\n",
    "Cross Correlation:\n",
    "\n",
    "Voxel:\n",
    "\n",
    "CN:\n",
    "    indexes: \n",
    "        69: [ s_1_v, s_2_v, ... ,  900]\n",
    "        53: [ s_1_v, s_2_v, ... ,  900]\n",
    "        98: [ s_1_v, s_2_v, ... ,  900]\n",
    "        99: [ s_1_v, s_2_v, ... ,  900]\n",
    "\n",
    "AD: \n",
    "    indexes: \n",
    "        69: [ s_1_v, s_2_v, ... ,  900]\n",
    "        53: [ s_1_v, s_2_v, ... ,  900]\n",
    "        98: [ s_1_v, s_2_v, ... ,  900]\n",
    "        99: [ s_1_v, s_2_v, ... ,  900]\n",
    "\n",
    "Global Metrics:\n",
    "\n",
    "    1 array of Global Metric of CN Vs ith index of Voxel count\n",
    "\n",
    "CN:\n",
    "Global:\n",
    "GE -> 53 Values\n",
    "CPL -> 53 Values\n",
    "CC -> 53 Values\n",
    "\n",
    "Component:\n",
    "DE -> 53 values\n",
    "CCE -> 53 Values\n",
    "PC -> 53 Values\n",
    "        0 1 2 3 4 5 6 7 8 ................\n",
    "    GE\n",
    "    CPL\n",
    "    CC\n",
    "    DE\n",
    "    CCE\n",
    "    PC\n",
    "\n",
    "AD -> \n",
    "\n",
    "\n",
    "MCI ->\n",
    "\n",
    "\n",
    "Difference FNC matrix:\n",
    "\n",
    "CN:\n",
    "res - 53x53\n",
    "sub1 -> 53x53 + res\n",
    "sub2 -> 53x53 + res\n",
    "\n",
    "avgFNC matrix - 900 subjects\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
